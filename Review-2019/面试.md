UMC项目 
三棵树：
首先采集一线数据采集过来 分析给一线的工程师看
springcloud redis 负载均衡 python eureka
数据库用的mysql linux
负责的工作主要有三个 
数据解析
1、拿到日志文件用正则表达式解析出来 放到数据库
2、调用自己的python接口，分析服务
3、python原子函数用于解析日志里的数据是怎样的结果
用了多线程，在解析中有多个日志文件，用了多线程异步解析 通知前台 使解析速度加快，大数据文件原来要用半个小时的 只用5分钟完成
解析完后 根据前端选择分析什么故障 通过分析服务接口调用python原子函数 （发送id 原子函数名称给原子函数进行处理）
python拿到数据后，对数据进行一定的判断处理，是否存在异常，并返回前端结果

因为每次用户打开看都会有许多异常数据，每次拿的时候都要查询数据库，加载页面缓慢，所以用到了redis

因为一线员工用户数量数据庞大 1千人左右，由于服务器配置低，所以放到三台服务器上
如何提高查询效率
1、数据库：由于数据量庞大，将每一个任务数据，根据日志数据大小，分区建表，数据量大的日志分为5个区，数据量小的分为2个区，缓解查询压力
有hash list range 分区，我用了list 和range根据id分区 
2、建索引（索引类型：常用的有唯一索引unique和primary主键索引，还有一些全文索引、组合索引其他不是太了解）
3、常用字段写在前面

sql：提高查询效率：不要写select *；不要写冗余查询字段；使用where的时候通配符不能放在后面要写前面，查的结果有连续值使用between和in，between效果好一点；
尽量用索引查询效率会提高很多
调用

arraylist索引值变化，hashset有key地址区存放所以遍历可以增删改
广义集合包括list和hash
狭义就是list 里面包括很多实现 arraylist linkedlist set 分了hashset

java内存 堆存放对象， 栈存放方法引用和常量
老年代 新生代 
GC：响应快多核CPU：CMS收集器（GC操作主要是分标记清除整理三个阶段，不对老年代整理碎片提高运行效率，标记清除阶段大部分工作和用户线程并发执行，减少停顿时间，缺点是老年代碎片）
并行GC 吞吐量减少停顿：不适合低延迟，适用于后台计算、弱交互场景 标记复制算法
G1收集器不是太了解


工厂模式解决重复造齿轮问题，单例模式

mybatis 工厂模式、代理模式调用

多线程有几个阶段：创建、启动、等待、返回、完成